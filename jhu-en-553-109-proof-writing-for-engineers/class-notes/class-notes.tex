\documentclass[11pt]{article}

% Document settings, taken from Introduction to Algorithms (Dinitz).
\usepackage{epsfig}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{fullpage}
\usepackage{enumitem}                     
\usepackage{titlesec}
\usepackage{amsthm}
\usepackage{natbib}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\titleformat*{\section}{\bfseries}
\titleformat*{\subsection}{\bfseries}
\titleformat*{\subsubsection}{\bfseries}
\titleformat*{\paragraph}{\bfseries}
\titleformat*{\subparagraph}{\bfseries}

\newcommand{\R}{\ensuremath{\mathbb R}}
\newcommand{\C}{\ensuremath{\mathbb C}}
\newcommand{\N}{\ensuremath{\mathbb N}}
\newcommand{\F}{\ensuremath{\mathbb F}}
\newcommand{\K}{\ensuremath{\mathbb K}}
\newcommand{\Z}{\ensuremath{\mathbb Z}}
\newcommand{\B}{\ensuremath{\mathcal B}}
\newcommand{\X}{\ensuremath{\mathcal X}}
\newcommand{\Y}{\ensuremath{\mathcal Y}}
\renewcommand{\S}{\ensuremath{\mathcal S}}
\renewcommand{\H}{\ensuremath{\mathcal H}}
\newcommand{\EV}{\ensuremath{\mathbb E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\e}{\epsilon}
\newcommand{\E}{\exists}
\newcommand{\sse}{\subseteq}
\newcommand{\union}{\cup}
\newcommand{\ra}{\rightarrow}
\newcommand{\ceil}[1]{\ensuremath{\left\lceil#1\right\rceil}}
\newcommand{\floor}[1]{\ensuremath{\left\lfloor#1\right\rfloor}}
\newcommand{\ip}[2]{\left\langle #1, #2\right\rangle}
\DeclareMathOperator*{\argmax}{arg\,max\ }
\DeclareMathOperator*{\argmin}{arg\,min\ }

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{coro}{Corollary}[section]
\newtheorem{obs}{Observation}[section]

\theoremstyle{definition}
\newtheorem{defi}{Definition}[section]

\theoremstyle{remark}
\newtheorem{exm}{Example}[section]
\newtheorem{exc}{Exercise}[section]
\newtheorem{rem}{Remark}[section]
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}

\setenumerate[0]{label=(\alph*)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%% Document begins here %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

% EDIT THE FOLLOWING PARAMETERS FOR EACH ASSIGNMENT.

% NAME and COURSE TITLE + SECTION NUMBER
\noindent {\large {\bf Mathematical Thinking and Proof-Writing for Engineers}} \hfill {\bf Intersession 2020}

% PROFESSOR and HOMEWORK NUMBER
\noindent {{\bf Instructor:} Ronak Mehta} \hfill 
{Class Notes}

\noindent \rule[0.1in]{\textwidth}{0.4pt}

% CONTENT

\section{January 6, 2020}

\paragraph{Prereading} \href{https://drive.google.com/drive/folders/1T_M-dvYE4leOSmpKt2eGYOvPRch_SDpK?usp=sharing}{Pages 1 - 11} of {\it Mathematics: A Discrete Introduction} by Edward Scheinerman. Also look at the ``Set Notation" PowerPoint in the repo.

\subsection{Introduction}
Welcome, and thanks for your interest! While mathematical theory is usually not the poster boy of engaging and topical intersession courses, I think we can change some minds with this particular class. The subject is fascinating, but notoriously difficult to teach. There are many balancing acts when it comes to mathematical education; those of memorization versus exploration, theory versus application, and lectures versus self-guided learning constitute most of the battle. In any case, I can make a strong argument for the utility of this course in your future endeavors, so I'll attempt to present it in a way that is best for you. To this end, I ask of you all a healthy amount of honest and constructive feedback throughout the course.

As a brief introduction, I recently graduated from the Master's program in Applied Mathematics and Statistics at Hopkins in May. Generally, I have focused my education around the mathematical foundations of data science - namely statistics, linear algebra, and optimization. I currently work in the \href{https://neurodata.io/}{lab of Dr. Joshua Vogelstein} in the Department of Biomedical Engineering, where I develop statistical procedures for neuroimaging data. I've also recently gone through a round of Ph.D. applications in data science, so hopefully you will hear some good news over the course of this class!

First, let us motivate this class, both in a general sense, and a way that applies to you directly. The most recent \href{https://hechingerreport.org/what-2018-pisa-international-rankings-tell-us-about-u-s-schools/}{Programme for International Student Assessment (PISA)} in 2018 ranked the U.S. at 36th out of 79 countries in mathematics. For decades, American math proficiency has compared abysmally to other developed nations, and since the 1980's the ``\href{https://en.wikipedia.org/wiki/Math_wars}{math wars}" debate pits rote memorization versus inquiry-based approaches to learning. I am personally unconvinced that such a dichotomy exists, given how many American debates typically present only two, fundamentally opposing options against one another. Moreover, these kinds of assessments come from a place of ``\href{http://neatoday.org/2019/12/03/2018-pisa-results/}{mental Olympics}" competitions for countries, as well as a measure of how prepared students are for a modern job market.  While this is a fine perspective, also consider the beauty and virtue that mathematics holds in and of itself. 

Paul Lockhart, in his book {\it A Mathematician's Lament}, compares current mathematics education to a dystopian version of teaching music.\\
\setlength{\leftskip}{1cm}

Since musicians are known to set down their ideas in the form of sheet music, these curious black dots and lines must constitute the ``language of music.” It is imperative that students become fluent in this language if they are to attain any degree of musical competence; indeed, it would be ludicrous to expect a child to sing a song or play an instrument without having a thorough grounding in music notation and theory. Playing and listening to music, let alone composing an original piece, are considered very advanced topics and are generally put off until college, and more often graduate school...

In the higher grades the pressure is really on. After all, the students must be prepared for the standardized tests and college admissions exams. Students must take courses in Scales and Modes, Meter, Harmony, and Counterpoint. ``It’s a lot for them to learn, but later in college when they finally get to hear all this stuff, they’ll really appreciate all the work they did in high school.” Of course, not many students actually go on to concentrate in music, so only a few will ever get to hear the sounds that the black dots represent. Nevertheless, it is important that every member of society be able to recognize a modulation or a fugal passage, regardless of the fact that they will never hear one. ``To tell you the truth, most students just aren’t very good at music. They are bored in class, their skills are terrible, and their homework is barely legible. Most of them couldn’t care less about how important music is in today’s world; they just want to take the minimum number of music courses and be done with it. I guess there are just music people and non-music people. I had this one kid, though, man was she sensational! Her sheets were impeccable— every note in the right place, perfect calligraphy, sharps, flats, just beautiful. She’s going to make one hell of a musician someday.”\\

\setlength{\leftskip}{0pt}

Proof-writing is the fabric of true mathematics, where we put aside canned procedures and dig into our creativity. In fact, to my knowledge, math is the only arena where participants can truly discuss ideas with pure, irrefutable logic. Other settings, such as courtrooms and debate clubs may come close, but there is always an element of qualification, uncertainty, or human emotion in the mix. It is entirely possible to just have fun with mathematics, and our education system should reflect that. (What are your thoughts?)

Bringing the discussion back to home base, you all will take one of either automata, algorithms, kinematics, signal processing, or even graduate AMS courses in the near future. Being successful in these settings will rely on a deep mathematical foundation. Ren\'e Vidal (data science professor in the BME department) often tells his advisees that there is a moment where these previously disparate concepts really click, and learning math becomes easy and natural. My goal is that this happens for each of you during this course. We will be experimenting in two ways. First, we will shy away from the dichotomy of memorization and experimentation. Instead, while there are certain definitions I will ask you to memorize and have available for rapid recall, I will also observe and refine the way you tackle new problems. I hope that as a result, you achieve a flexible, enduring problem-solving approach. Second, class meetings will include both example problems that I will do, and exercise problems that you will do. As of now, I do not plan to have required homework besides some readings but will give you plenty of practice problems to work through together as the class goes on.

The class will include topics from Chapter 1 and 2 of {\it Mathematics: A Discrete Introduction} by Ed Scheinerman and most of {\it A Problem Book in Real Analysis} by Aksoy and Khamsi, which you can find \href{https://drive.google.com/drive/folders/1T_M-dvYE4leOSmpKt2eGYOvPRch_SDpK?usp=sharing}{here}. I really like both of them, especially due to their concision and clarity. Real analysis  is a course typically taken by math majors in their sophomore years. Some describe it as “Calc I done right”, in the sense of introducing similar topics but proving and deriving every result along the way. While there are many ways to practice proof-writing, I chose this particular content as to directly apply to graduate applied math courses, and practice heavily without introducing too much material. This includes proof strategies, sequences and series, limits, continuity, and point-set topology. We can add more content that is interesting to you as time permits. We will start off slow and basic, but things will ramp up quickly. Enjoy!

\subsection{Notation}

Descriptive and consistent notation supports understanding, so I will harp on notation (and terminology) slightly as we work through certain topics. However, we will do so as new topics are introduced, rather than all at once. If it is a helpful analogy, consider nomenclature in an organic chemistry class.

\subsection{Definitions, Theorems, Proofs}

% Before we get into the real nature of the course, we'll start with some visual examples to describe the kind of reasoning I we all develop. At some point in elementary school, you were told to accept that the circumference of a circle $C = 2\pi R$ where $R$ is the radius. This we can believe was discovered by measurement. However, we are also told that the area of a circle $A = \pi R^2$, volume of a sphere $V = \frac{4}{3} \pi R^3$, and the surface area of a sphere $S = 4 \pi R^2$. Let's start with something simpler, the area of a triangle $A_T = \frac{1}{2}bh$, where $b$ is the length of the base, and $h$ is the height.figure \ref{triangle} shows that splitting a scalene triangle into two right triangles makes clear why the formula holds. Letting the left base be $b_1$ and the right base be $b_2$, and noting that the right triangle's area is half that of the rectangle in which it is contained, we have
% \begin{align*}
%     A_T &= \frac{1}{2}b_1h + \frac{1}{2}b_2h\\
%     &= \frac{1}{2}(b_1 + b_2)h\\
%     &= \frac{1}{2}bh
% \end{align*}
% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\linewidth]{figures/triangle.png}
%     \caption{We are interested in the area of the orange triangle, which has been split into two.}
%     \label{triangle}
% \end{figure}
% Similarly, we have the celebrated Pythagorean theorem, another formula we have been told to believe. Let $a$ and $b$ be two legs of a right triangle, and $c$ the hypotenuse. We know that $a^2 +b^2 = c^2$. How can we prove this? Take a look at Figure \ref{pyt}, and compute the area of 4 of these right triangles, both individually and by constructing a large square and subtracting the area of the square in the middle.
% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\linewidth]{figures/pythagorean.png}
%     \caption{Compute the area of the colored region both ways to prove the theorem.}
%     \label{pyt}
% \end{figure}
% \begin{align*}
%     4 \frac{1}{2} ab &= (a + b)^2 - c^2\\
%     2ab &= a^2 + 2ab + b^2 - c^2\\
%     c^2 &= a^2 + b^2
% \end{align*}

% Let's get back to the area of a circle. One of the most commonly known proofs is from about two thousand years ago by Archimedes (260 B.C.E.). For an $n$ side regular polygon , its area is going to be $A_n = \frac{1}{2} p_n a_n$, where $p_n$ is the perimeter and $a_n$ is the apothem (distance from center to midpoint of one of the sides). See \href{https://en.wikipedia.org/wiki/Area_of_a_circle#Archimedes's_proof}{Wikipedia} for the full proof. As in Figure \ref{circle}, the inscribed polygon will have perimeter approaching $2\pi R$, and apothem approaching $R$, as $n \rightarrow \infty$. The inscribed polygon also has less area than the circle. Letting $A$ be the area of the circle, we have
% \begin{align*}
%     A \geq \frac{1}{2} p_n a_n
% \end{align*}
% Taking the limit of both sides as $n$ gets large, we have
% \begin{align*}
%     A \geq \frac{1}{2} 2 \pi R \cdot R = \pi R^2
% \end{align*}
% For the circumscribed polygon, the apothem is always $R$, and the perimeter also approaches $2\pi R$. Thus,
% \begin{align*}
%     A \leq \frac{1}{2} p_n a_n = \frac{1}{2} p_n R
% \end{align*}
% Taking the limit once again, we have
% \begin{align*}
%     A \leq \frac{1}{2} 2 \pi &R \cdot R = \pi R^2\\
%     \implies \pi R^2 &\leq A \leq \pi R^2
% \end{align*}
% proving the area formula.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\linewidth]{figures/inscribed.png}
%     \includegraphics[width=0.6\linewidth]{figures/circumscribed.png}
%     \caption{The first panel shows an inscribed polygon, while the second shows the circumscribed polygon. Both approach the circle in area.}
%     \label{circle}
% \end{figure}


{\it Informal picture ``proofs" of area of triangle, Pythagorean theorem, area of a circle, volume of a sphere, and surface area of a sphere.}\\

Ed Scheinerman, currently the dean of our engineering school, can set the stage for you much better than I can. I especially like the first ten pages. Assuming that you've read through the chapter, you have come across definitions, theorems, and some basic proofs. We will not define ``definition" but take it as an introduction or a name of a mathematical object. In future classes, these should always be memorized and be able to be retrieved from your brain upon request. In order to understand, you must first memorize a little bit. On the other hand, theorems are declaritive statements which can be written of the form ``If [assumptions], then [conclusion]". More on this later.

\begin{defi}[Set]
    A set is a collection of unordered, distinct objects. 
\end{defi}
Sets can have a finite or infinite number of elements, and are usually denoted by capital letters. We can list their elements out one-by-one and wrap then in curly braces, or specify them by some condition, as in $\{x : \text{ condition regarding $x$ is true.}\}$. For example, 
\begin{align*}
    A = \{1, 2, 3, 6, 7\}
\end{align*}
is a set of 5 elements. Letting $\Z = \{..., -1, 0, 1, ...\}$ be the set of all integers, I can denote the same set by
\begin{align*}
    A = \{x \in \Z: 0 < x < 4 \text{ and } 5 < x < 8\}
\end{align*}
The colon within the braces can be read as ``such that". Let $\N = \{0, 1, 2, ...\} = \{x \in \Z: x \geq 0\}$ be the set of natural numbers, or nonnegative integers. Let's recall some definitions from the chapter.
\begin{defi}[Divisible]
    An integer $b$ is divides integer $a$ (written $b \mid a$) if there is an integer $c$ such that $a = bc$. $a$ is called a multiple of $b$, and is also called divisible by $b$. $b$ is also called a divisor or factor of $a$. 
\end{defi}
\begin{defi}[Even]
    An integer $a$ is called even if it is divisible by 2.
\end{defi}
\begin{defi}[Odd]
    An integer $a$ is called odd if there is an integer $x$ such that $a = 2x + 1$.
\end{defi}
\begin{defi}[Prime]
    An integer $p$ is called prime if $p > 1$ and the only positive divisors of $p$ are 1 and $p$.
\end{defi}
\begin{defi}[Composite]
    An integer $c$ is called composite if $c > 1$ and $c$ is not prime. We can also say integer $c > 1$ is composite if there exists a factor $b$ such that $1 < b < c$.
\end{defi}

While none of these concepts are particularly interesting in their own right, they are probably familiar to you. More importantly, with just these definitions, we have a huge class of problems with which to jump in and warm up. 

\begin{exc}
    Prove that the sum of two even integers is even.
\end{exc}
\begin{exc}
    Prove that integer $x$ is even if, and only if, $x + 1$ is odd.
\end{exc}
\begin{exc}
    Prove that the product of an odd and even integer is even.
\end{exc}
\begin{exc}
    Prove that square of an odd integer is odd.
\end{exc}
\begin{exc}
    Prove that square of a prime number is composite.
\end{exc}
\begin{exc}
    Prove that the sum of three consecutive integers is divisible by 3.
\end{exc}
\begin{exc}
    Let $a,b, c$ be integers. Prove that if $a \mid b$ and $b \mid c$, then $a \mid c$.
\end{exc}
\begin{exc}
    Prove that if $n$ is odd, then $-n$ is odd.
\end{exc}
\begin{exc}
    Let $a,b, c$ be integers. Prove that if $a \mid b$ and $a \mid c$, then $a \mid (b+c)$.
\end{exc}
\begin{exc}
    Let $a,b, c$ be integers. Prove that if $a \mid b$ and $a \mid c$, then $a \mid (bc)$.
\end{exc}
\begin{exc}
    Prove that the difference between consecutive perfect squares is odd.
\end{exc}

\begin{exm}
    Let $x$ be an integer. If $x > 1$, then $x^3 + 1$ is composite.
\end{exm}
\begin{proof}
    See page 19 of Scheinerman.
\end{proof}

\begin{exc}
    Provide two conditions $A$ and $B$ such that
    \begin{itemize}
        \item If $A$, then $B$ is true.
        \item If $B$, then $A$ is false.
    \end{itemize}
\end{exc}
\begin{exc}
    Say that you are asked to prove "If $A$ or $B$, then $C$". Why must you show BOTH $A \implies C$ and $B \implies C$? Why not just one?
\end{exc}
\begin{exc}
    Give a counterexample of the ``SSA" postulate for triangle congruence.
\end{exc}
\begin{exc}
    A perfect number is an integer whose divisors add up to the number. For example, $28 = 1 + 2 + 4 + 7 + 14$. Find a perfect number less than 28. Is it the only one? {\it Hint: Try adding additional constraints, such as the number having only two prime factors. Is this a good assumption to make?}
\end{exc}
\begin{exc}
    Disprove: Let $a, b$ be integers. $a \mid b$ and $b \mid a \implies a = b$.
\end{exc}
\begin{exc}
    Disprove: Let $a, b$ be integers. $a \mid b \implies a \leq b$.
\end{exc}
\begin{exc}
    Disprove: Two right triangles have the same area if and only if the lengths of their hypotenuses are the same.
\end{exc}
\begin{exc}
    Disprove: A positive integer is composite if and only if it has two different prime factors.
\end{exc}

\section{January 7, 2020}

Beyond direct proof, there are two more proof strategies that use a slightly different approach. The statement we wish to show typically look like $A \implies B$, or ``If condition $A$ is true, then condition $B$ is true". Another way one can show this is by {\it assuming} that $A$ is true and $B$ is false, and showing that this contradicts some previously held belief. You can read more about this in Scheinerman Chapter 4, Section 20.
\begin{exm}
    Prove that no integer is both even and odd.
\end{exm}
\begin{proof}
    Assume for the sake of contradiction (FSOC) that $x \in \Z$ is both even and odd. In other words, $\exists a, b \in \Z$ such that $x = 2a$ and $x = 2b+1$. Then,
    \begin{align*}
        2a &= 2b+1\\
        \implies 2(a-b) &= 1\\
        \implies a-b &= \frac{1}{2}
    \end{align*}
    But this is absurd, as $a-b$ must be an integer. Therefore, our original assumption is false, and $x$ cannot be both even and odd.
\end{proof}
\begin{exc}
    Prove by contradiction: If the sum of two primes is prime, then one of the primes must be 2.
\end{exc}
\begin{exc}
    Let a be a number with a > 1. Prove that $\sqrt{a}$ is strictly between 1 and a.
\end{exc}

On the other hand, statements proved with the principle of induction usually look like "Prove that $l(n) \sim r(n)$ for all $n \geq 1$, where $l(n)$ and $r(n)$ are expressions of $n$, and the ``$\sim$" symbol relates them in some way.
\begin{exm}
    Prove that $1 + 2 + ... + n = \frac{n(n+1)}{2}$.
\end{exm}
In this scenario, we show two things.
\begin{enumerate}
    \item $l(1) \sim r(1)$
    \item If $l(k) \sim r(k)$, then it must be true that $l(k+1) \sim r(k+1)$.
\end{enumerate}
This makes it so that $l(1) \sim r(1) \implies l(2) \sim r(2) \implies ...$, showing the result for all $n$.
\begin{proof}
    Clearly, $1 = \frac{1(1+1)}{2}$. Say $1 + 2 + ... + k = \frac{k(k+1)}{2}$ for some $k \geq 1$. Then,
    \begin{align*}
        1 + 2 + ... + k + (k+1) &= (1 + 2 + ... + k) + (k+1)\\
        &= \frac{k(k+1)}{2} + (k+1)\\
        &= \frac{k(k+1)}{2} + \frac{2(k+1)}{2}\\
        &= \frac{k(k+1) + 2(k+2)}{2}\\
        &= \frac{(k+2)(k+1)}{2}\\
        &= \frac{(k+1)(k+1+1)}{2}
    \end{align*}
\end{proof}
You can read more about this strategy in Scheinerman Chapter 4 Section 22.

\begin{exc}
    Prove that $1^2 + 2^2 + ... +n^2 = \frac{(2n+1)(n+1)n}{6}$ for $n \geq 1$.
\end{exc}
\begin{exc}
    Prove that $1\cdot 1! + 2\cdot 2! + ... + n \cdot n! = (n+1)! - 1$ for $n \geq 1$.
\end{exc}
\begin{exc}
    Prove that $10^0 + 10^1 + ... +10^n < 10^{n+1}$ for $n \geq 0$.
\end{exc}

\section{January 8, 2020}

So far, we have seen three main proof strategies and steps. 
\begin{itemize}
    \item Direct Proof: $A \implies B$ (including contrapositive $\neg B \implies \neg A$).
    \begin{enumerate}
        \item Unravel definitions of conclusion or want-to-show (W.T.S.)
        \item Unravel definitions of assumptions.
        \item "Aha!" moment, where algebraic manipulations bridge the gap.
    \end{enumerate}
    \item Proof by Contradiction: $A$ and $\neg B \implies $ absurdity.
    \begin{enumerate}
        \item Unravel definitions of assumptions.
        \item ``Assume FSOC..." Unravel definitions of negated conclusion
        \item Contradict some aspect of the original problem set up.
    \end{enumerate}
    \item Proof by Induction: $l(n) \sim r(n)$ for $n \in \N$
    \begin{enumerate}
        \item Show that $l(1) \sim r(1)$ (or some equivalent base case).
        \item Show that if $l(k) \sim r(k)$, then it must be true that $l(k+1) \sim r(k+1)$. This usually involves...
        \begin{enumerate}
            \item Writing down $l(k+1)$.
            \item Turning it into an expression involving $l(k)$.
            \item Replacing $l(k)$ be $r(k)$ (in a way that makes sense with whatever ``$\sim$" is).
            \item Turning the resulting expression into $r(k+1)$.
        \end{enumerate}
    \end{enumerate}
\end{itemize}

Believe it or not, all of the logic that you will probably see in your mathematical careers is listed above. The only thing that becomes more complicated as you get to more advanced math is the definitions, which you will memorize diligently. Otherwise, direct, contradiction, and induction proof really cover everything. So we will drill them today so that you are completely solid on them, and then we will move on and see complex definitions and applications of these ideas. I'll first introduce sum and product notation if you haven't seen it before.

\subsection{Sums and Products}

A {\it list} is an ordered collection of elements, as opposed to a {\it set}, which is an unordered, collection of distinct elements. We typically write this as $(a_i)_{i=1}^n = (a_1, a_2,..., a_n)$. The subscript $i$ for $i = 1, 2,..., n$ indexes the $i$-th element of this list. Assuming that we are dealing with a list of real numbers, say, the sum of the list is written:
\begin{align*}
    S = \sum_{i=1}^n a_i = a_1 + a_2 + ... + a_n
\end{align*}
$i$ is called the index variable, and any variable can be used for this purpose; $i$, $j$, and $k$ are common ones (similar to a ``dummy" variable in integration). If we multiply each element by a constant $k$, the sum also increases by factor $k$. Using this information, we can pull constants (values that do not have the index variable as a subscript) out of the sum. If a list $(c_i)$ can be decomposed into a sum of two lists $(a_i)$ and $(b_i)$, we can sum them individually.
\begin{align*}
    \sum_{i=1}^n ka_i = ka_1 +ka_2 + ... + ka_n &= k(a_1 + a_2 + ... + a_n) = k\sum_{i=1}^n a_i\\
    \sum_{i=1}^n c_i = \sum_{i=1}^n (a_i + b_i) &= \sum_{i=1}^n a_i + \sum_{i=1}^n b_i
\end{align*}
The sum of an empty list of numbers has size 0.\\

Similar to sums, we may want to multiply all elements of a list into one product. We write this as:
\begin{align*}
    P = \prod_{i=1} a_i = a_1 \cdot a_2 \cdot ... \cdot a_n
\end{align*}
When pulling out a constant $k$, we must raise it to the $n$-th power, because it scales the total product once {\it per element}. Similarly, if a list $\{c_i\}$ is an element-wise product of lists $\{a_i\}$ and $\{b_i\}$, then we can take the products individually and multiply them.
\begin{align*}
    \prod_{i=1}^n ka_i = (ka_1)\cdot(ka_2)\cdot ... \cdot (ka_n) &= k^n \cdot (a_1 \cdot a_2 \cdot ... \cdot a_n) = k^n \prod_{i=1}^n a_i\\
    \prod_{i=1}^n c_i = \prod_{i=1}^n (a_i b_i) &= \left(\prod_{i=1}^n a_i \right) \cdot \left(\prod_{i=1}^n b_i\right) 
\end{align*}
The product of an empty list has value 1.

\subsection{Direct Proof and Logic Problems}

\begin{exc}
    Let $a$ and $b$ be positive integers. Explain why the notation $a \mid b+1$ can be interpreted only as $a \mid (b+1)$ and not as $(a \mid b) + 1$.
\end{exc}
\begin{exc}
    Suppose $a$ is a perfect square and $a \geq 9$. Prove that $a-1$ is composite.
\end{exc}

\subsection{Proof by Contradiction Problems}

\begin{exc}
    Prove that $\sqrt{2}$ is irrational, i.e. there are no $p, q \in \Z$ such that $\sqrt{2} = \frac{p}{q}$.
\end{exc}
\begin{exc}
    Prove that there exist no integers $a, b$ such that $18a + 6b = 1$.
\end{exc}
\begin{exc}
    Suppose that $a, b \in \Z$. Prove that if $4 \mid a^2 + b^2$, then $a$ and $b$ cannot both be odd.
\end{exc}
\begin{exc}
    Prove there are infinitely many prime numbers.
\end{exc}
\begin{exc}
    Let $a \in \Z$. Prove that if $a^2$ is even, then $a$ is even.
\end{exc}

\subsection{Proof by Induction Problems}

\begin{exc}
    Prove that $\sum_{k=1}^n (2k-1) = n^2$.
\end{exc}
\begin{exc}
    Suppose $a \neq 1$. Prove that $\sum_{j=0}^n a_j = \frac{a^{n+1} - 1}{a-1}$.
\end{exc}
\begin{exc}
    Prove that $n! > 2^n$ for all $n \geq 4$.
\end{exc}
\begin{exc}
    Prove that $\prod_{j=1}^n \frac{j^2}{j+1} = \frac{n!}{n+1}$.
\end{exc}
\begin{exc}
    Prove that $\sum_{k=1}^n \frac{1}{k^2} < 2 - \frac{1}{n}$ for $n \geq 1$.
\end{exc}
\begin{exc}
    Prove $\sum_{r=1}^n r(r+1) = \frac{1}{3} n(n+1)(n+2)$
\end{exc}
\begin{exc}
    Prove $\sum_{r=1}^n r(r+1)(r+1)...(r+p-1) = \frac{1}{1+p} n(n+1)(n+2)...(n+p)$. We can also write this as
    \begin{align*}
        \sum_{r=1}^n \prod_{l=1}^p r(r+l-1) = \frac{1}{1+p} \prod_{l=0}^p (n+l)
    \end{align*}
\end{exc}
\begin{exc}
    Prove that $4^n - 1$ is divisible by 3 for all $n \geq 1$.
\end{exc}
\begin{exc}
    Prove that $5^{2n+1} + 2^{2n+1}$ is divisible by 7 for all $n \geq 0$.
\end{exc}
\begin{exc}
    Let $A_1, ..., A_n$ be sets (where $n \geq 2)$. Suppose that for any two sets $i$ and $j$, either $A_i \subseteq A_j$ or $A_j \subseteq A_i$. Prove by induction that one of the $n$ sets is a subset of all of them.
\end{exc}
\begin{exc}
    A group of people stand in line to purchase movie tickets. The first person in line is a woman and the last person in line is a man. Use proof by induction to show that somewhere in the line a woman is directly in front of a man.
\end{exc}
\begin{exc}
    Proposition 22.10 from Scheinerman.
\end{exc}
\begin{exc}
    Problem 22.12 from Scheinerman (Tower of Hanoi).
\end{exc}


\section{January 9, 2020}

Our first example will get us acquainted to the conceptual and rigorous difficulty that comes with infinity, especially with regard to sizes of sets or limits of sequences and functions. This \href{https://www.youtube.com/watch?v=Uj3_KqkI9Zo}{TED-Ed video} can explain the Hilbert Hotel problem best. The solutions in the video make use of the infinite number of primes, which we can prove.
\begin{exm}
    Prove that there are an infinite number of prime numbers.
\end{exm}
\begin{proof}
    Assume for the sake of contradiction, that there are finitely many, $n$ primes, denoted $p_1, ..., p_n$. Consider the number $q = p_1 p_2 ... p_n + 1$. This number cannot be prime, as it is greater than all of the prime numbers listed. Thus, it is divisible by at least one of the primes, and without loss of generality we can call that prime $p_1$. By the definition of division, there exists some $c \in \Z$ such that
    \begin{align*}
        q &= p_1 c\\
        p_1 p_2 ... p_n + 1 &= p_1 c\\
        p_2 ... p_n + \frac{1}{p_1} &= c\\
        \frac{1}{p_1} &= c - p_2 ... p_n \in \Z
    \end{align*}
    It appears that $\frac{1}{p_1}$, a non-integer, is equal to the integer $c - p_2 ... p_n$. This is absurd, meaning our original assumption of finitely many primes must be false.
\end{proof}
The ``flavor" of infinite explored in the video is called {\bf countable} infinity, i.e. the number of elements that can be laid out in an infinitely long list. 
\begin{defi}[Countable]
    A set $S$ is called countably infinite (or countable) if all of its elements can be uniquely paired with elements of $\N$. (If you are aware of the term, we say that there is a bijection between $S$ and $\N$.)
\end{defi}
\begin{defi}[Uncountable]
    A set $S$ is called uncountably infinite (or uncountable) if it is infinite and is not countable.
\end{defi}
An example of a countable set is the integers $\Z$. We can show this by simply stating a pattern that will name every element of the set if continued long enough.
\begin{exm}
    Prove that $\Z$ is countable.
\end{exm}
\begin{proof}
    Count the elements as $0, 1, -1, 2, -2, 3, -3, ...$. 
\end{proof}
While it would be nicer to give the exact function that produces the elements of $\Z$, it's not entirely necessary if the point is clear.
\begin{defi}[Power Set]
    The power set of set $A$, denoted $2^A$, is the set of all subsets of $A$ (including $A$ and the empty set $\emptyset$).
\end{defi}
For example, the power set of $A = \{a_1, a_2, a_3\}$ is going to be 
\begin{align*}
    2^A = \{\emptyset, \{a_1\}, \{a_2\}, \{a_3\}, \{a_1, a_2\}, \{a_1, a_3\}, \{a_2, a_3\}, \{a_1, a_2, a_3\}\}
\end{align*}
We will employ something called the Cantor Diagonal Argument to prove that $2^{\N}$ (set of all subsets of natural numbers) is uncountable.
\begin{exm}
    Prove that $2^{\N}$ is uncountable.
\end{exm}
\begin{proof}
    First, we can index each element of $2^{\N}$ by a binary string of zeroes and ones, indicating which elements of $\N$ are included in the set. For example, we can write:
    \begin{center}
    \begin{tabular}{ |c|c c c c c| } 
         \hline
         Subset & 1 & 2 & 3 & 4 & ... \\ 
         \hline
         $s_1$ & 0 & 0 & 0 & 0 & ... \\ 
         $s_2$ & 0 & 1 & 1 & 0 & ... \\
         $s_3$ & 1 & 0 & 0 & 1 & ... \\
         $s_4$ & 0 & 1 & 1 & 1 & ... \\
         ... & ... & ... & ... & ... & ... \\
         \hline
    \end{tabular}
    \end{center}
    A one in position $j$ of $s_i$ indicates that $j$ is included in subset $i$. Assuming that the $...$ means that the remaining elements are zeroes for each subset, we have that $s_1 = \emptyset, s_2 = \{2, 3\}$, $s_4 = \{2, 3, 4\}$, etc. If $2^{\N}$ truly is countable, we should be able to write every subset in this way, and list them in a (countable) infinity-by-infinity table. Consider the subset $s$ generated by taking the diagonal elements, and flipping them from zero to one and vice versa. That is, take the bold elements below.
    \begin{center}
    \begin{tabular}{ |c|c c c c c| } 
         \hline
         Subset & 1 & 2 & 3 & 4 & ... \\ 
         \hline
         $s_1$ & \bf 0 & 0 & 0 & 0 & ... \\ 
         $s_2$ & 0 & \bf 1 & 1 & 0 & ... \\
         $s_3$ & 1 & 0 & \bf 0 & 1 & ... \\
         $s_4$ & 0 & 1 & 1 & \bf 1 & ... \\
         ... & ... & ... & ... & ... & ... \\
         \hline
    \end{tabular}
    \end{center}
    Lay them out as $(0, 1, 0, 1, ...)$ and flip them, letting $s = (1, 0, 1, 0, ...)$. $s$ is different from every row of the table. Specifically, $s$ differs from subset $s_i$ at index $i$. This $s$ indexes a subset of $\N$, but is not included in the countable list $(s_1, s_2, s_3, ...)$. However, this list was supposed to include every element of $2^{\N}$. This is a contradiction, and the assumption that $2^{\N}$ was countable is false.
\end{proof}
The diagonal argument is cool, but deceptive. Consider the following statement and proof (both of which are clearly wrong), and try to find the flaw in the logic.
\begin{exm}[{\bf false}]
    Prove that $\N$ is uncountable.
\end{exm}
\begin{proof}
    For the sake of contradiction, assume that $\N$ is countable. We can index elements of $\N$ with strings of zeroes and ones, this time representing power of two that we add together to form numbers. Consider the following table.
    \begin{center}
    \begin{tabular}{ |c|c c c c c| } 
         \hline
         Subset & 1 & 2 & 4 & 8 & ... \\ 
         \hline
         $s_1$ & 0 & 0 & 0 & 0 & ... \\ 
         $s_2$ & 0 & 1 & 1 & 0 & ... \\
         $s_3$ & 1 & 0 & 0 & 1 & ... \\
         $s_4$ & 0 & 1 & 1 & 1 & ... \\
         ... & ... & ... & ... & ... & ... \\
         \hline
    \end{tabular}
    \end{center}
    So, in this case $s_1 = 0, s_2 = 2 + 4 = 6, s_3 = 1 + 8 = 9$, and $s_4 = 2 + 4 + 8 = 14$. Let $s$ be formed by reversing the diagonal $s = (1, 0, 1, 0, ...)$. Clearly, $s$ is not included in the list. Thus, our original assumption of countable $\N$ must be false.
\end{proof}

We will now move into sequences of real numbers and limits. This is a concept you have definitely seen in calculus, but likely have not rigorously defined yet.
\begin{defi}[Sequence]
    A sequence, denoted $x_1, x_2, ..., $, or $(x_n)_{n=1}^\infty$, or $(x_n)$, is a (countably) infinitely long list.
\end{defi}
You are already aware of the ability for sequences to ``approach" some limit as $n$ gets large. For example, it is intuitively clear, that $(\frac{1}{n})_{n=1}^\infty$ approaches 0 as its limit. Can you come up with a definition that can be used to definitively prove that a sequences $(x_n) \rightarrow x$?
\begin{defi}[Convergence and Limit]
    A sequence $(x_n)$ converges to limit $x$, if for all $\epsilon > 0$, there exists an $N$ (dependent on $\epsilon$) such that
    \begin{align*}
        \forall n \geq N, \quad |x_n - x| < \epsilon 
    \end{align*}
\end{defi}
Figure \ref{fig:conv} visually depicts the definition.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/limit.png}
    \caption{$a$ denotes the limit in this sequence, $N_0$ denotes $N(\epsilon_0)$ for some $\epsilon_0$, and $N_1 = N(\epsilon_1) < N_0$ for some $\epsilon_1 < \epsilon_0$.}
    \label{fig:conv}
\end{figure}
Proving that a sequences converges comes down to providing the $N$ that makes the terms $x_N, x_{N+1}, x_{N+2}, ...$ all be $\epsilon$-close to $x$.
\begin{exm}
    Prove that $(\frac{1}{n})_{n=1}^{\infty}$ converges to 0.
    \label{exm1}
\end{exm}
\begin{proof}
    Take an $\epsilon > 0$. We require that $|x_n - x| < \epsilon$.
    \begin{align*}
        |x_n - x| &= |\frac{1}{n} - 0|\\
        &= \frac{1}{n}\\
        &< \epsilon\\
        \implies n &> \frac{1}{\epsilon}
    \end{align*}
    So, choose $N$ to be any integer with $N > \frac{1}{\epsilon}$, and we will have that $\frac{1}{n} < \epsilon$ for all $n \leq N$. The result is shown.
\end{proof}
\begin{exm}
    Prove that $(e^{-n})_{n=1}^\infty$ converges to 0.
    \label{exm2}
\end{exm}
Before we continue, let us do some sanity checks (which I believe are really important in any math course). Because $e_{-n}$ decays to 0 {\bf faster} than $\frac{1}{n}$, we expect the $N$ that makes $e_{-n} < \epsilon$ (for all $n \geq N$) to be {\bf smaller} than that of $(\frac{1}{n})$. Why? For a fixed precision $\epsilon$, $e_{-n}$ should get $\epsilon$ away from zero at an earlier index of the sequence than $\frac{1}{n}$. Let's check if that is the case.
\begin{proof}
    Take an $\epsilon > 0$. We require that $|x_n - x| < \epsilon$.
    \begin{align*}
        |x_n - x| &= |e^{-n} - 0|\\
        &= e^{-n}\\
        &< \epsilon\\
        \implies n &> \ln \left(\frac{1}{\epsilon}\right)
    \end{align*}
    So, choose $N$ to be any integer with $N > \ln \left(\frac{1}{\epsilon}\right)$, and we will have that $e^{-n} < \epsilon$ for all $n \leq N$. The result is shown.
\end{proof}
This is what we expected. For reference, letting $\epsilon = 10^{-3}$, we have that $\frac{1}{\epsilon} = 1000$, while $\ln \left(\frac{1}{\epsilon}\right) \approx 7$.

\section{January 13, 2020}

While the definition of {\bf convergence} is beautiful in that it explains as aspect of infinity without ever mentioning it, there is a limitation. In order to say that $(x_n)$ converges, we must know its limit. An observation of sequences that converge might help us derive a necessary and sufficient condition for convergence (in $\R$) that does not require knowledge of the limit. Many sequences can be evaluated by computers for example, if the limit is known to exist.
\begin{defi}[Cauchy Sequence]
    A sequence $(x_n)$ is called Cauchy if for all $\epsilon > 0$, there exists an $N$ (dependent on $\epsilon$) such that
    \begin{align*}
        \forall k,l \geq N, \quad |x_k - x_l| < \epsilon 
    \end{align*}
\end{defi}
\begin{exm}
    Prove that $(\frac{1}{n})_{n=1}^\infty$ is Cauchy.
\end{exm}
\begin{exm}
    Prove that $(e^{-n})_{n=1}^\infty$ is Cauchy.
\end{exm}
We would like to approach the following equivalence result.
\begin{thm}
     A sequence in $\R$ converges if, and only if, it is Cauchy.
\end{thm}
\begin{proof}[Proof of forward direction.]
    We start by assuming sequence $(x_n)$ is convergent with limit $x$. Take any $\epsilon > 0$. Choose $N$ to be large enough such that $|x_n - x| < \frac{\epsilon}{2}$ for all $n \geq N$. Then, for $k, l \geq N$:
    \begin{align*}
        |x_k - x_l| = |x_k - x + x - x_l| \leq |x_k - x| + |x - x_k| \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
    \end{align*}
\end{proof}
\begin{exm}
    Prove that $(\frac{1}{n})_{n=1}^\infty$ is Cauchy.
\end{exm}
\begin{proof}
    Take any $\e > 0$. Choosing $N > \frac{2}{\e}$, and any $k, l \geq N$,
    \begin{align*}
        |x_k - x_l| &= \left|\frac{1}{k} - \frac{1}{l}\right| \leq \frac{1}{n} + \frac{1}{n} = \frac{2}{n} \leq \frac{2\epsilon}{2} = \epsilon
    \end{align*}
\end{proof}
\begin{exc}
    Prove that $(e^{-n})_{n=1}^\infty$ is Cauchy.
\end{exc}
\begin{defi}[Subsequence]
    Let $(x_n)$ be a sequence. Let $(n_k)_{k=1}^{\infty}$ be a sequence such that $n_1 < n_1 < n_3 < ...$ and each $n_k \in \N$. Then the sequence $(x_{n_k})_{k=1}^\infty$ is called a subsequence of $(x_n)$.
\end{defi}
\begin{exc}
    Prove that every subsequence of a convergent sequence converges (to the same limit).
\end{exc}
\begin{defi}[Bounded Sequence]
    A sequence $(x_n)$ in $\R$ is called bounded if $\E M > 0$ such that $|x_n| \leq M$ for all $n \in \N$.
\end{defi}
\begin{defi}[Monotone Sequence]
    A sequence $(x_n)$ in $\R$ is called monotone non-decreasing if $x_1 \leq x_2 \leq x_3 \leq ...$. Similarly, $(x_n)$ is called monotone non-increasing if $x_1 \geq x_2 \geq x_3 \geq ...$. $(x_n)$ is called monotone if it is either monotone non-increasing or monotone non-decreasing.
\end{defi}
\begin{thm}
    Every sequence in $\R$ has a monotone subsequence.
    \label{thm:mono}
\end{thm}
\begin{proof}
    Let $(x_n)$ be a sequence. Let a {\bf peak} of $(x_n)$ be an element $x_m$ such that if $n > m$, then $x_n < x_m$. That is, $x_m$ is greater than every element that comes after it. Consider two cases. 
    \begin{enumerate}
        \item There are infinitely many peaks $x_{m_1}, x_{m_2}, ...$ for $m_1 < m_2 < ...$. Then these peaks form a non-increasing subsequence, as $x_{m_1} \geq x_{m_2} \geq ...$.
        \item There are finitely many peaks. Let $x_M$ be the last peak. Let $m_1 = M + 1$ Then, $x_{m_1}$ is not a peak, and there exists an $m_2 > m_1$ such that $x_{m_1} \leq x_{m_2}$. $x_{m_2}$ is also not a peak. So there exists another $m_3 > m_2$ such that $x_{m_2} \leq x_{m_3}$. This pattern continues (and can be written inductively), to form a monotone non-decreasing sequence.
    \end{enumerate}
\end{proof}
We'll now present a result that you will show for homework.
\begin{thm}
    Every monotone and bounded sequence converges.
    \label{thm:monobound}
\end{thm}
Using the above ideas, we can prove the following.
\begin{thm}[Bolzano-Weirstrass]
    If a sequence is bounded, it has a convergent subsequence.
    \label{thm:bw}
\end{thm}
\begin{proof}
    By Theorem \ref{thm:mono}, we know that any sequence has a monotone subsequence. If the original sequence is bounded, so is every subsequence. Finally, such a subsequence would be monotone and bounded, thus convergent by Theorem \ref{thm:monobound}.
\end{proof}
Finally, using the above results, we are in a place to prove that Cauchy sequences converge in $\R$.
\begin{thm}
    If a sequence in $\R$ is Cauchy, then it converges.
\end{thm}
\begin{proof}
    We will tackle this in three steps. First, we show that the sequence is bounded. Then we show that the sequences has a convergent subsequence. Lastly, we show that the original sequence converges to the same limit as the subsequence. Let the Cauchy sequence be $(x_n)$.
    \begin{enumerate}
        \item Let $N$ be large enough such that for all $k, l \geq N$, we have that $|x_k - x_l| < 1$. This is possible by applying the definition of Cauchy for the particular case of $\e = 1$. Then, we know that for all $n \geq N$,
        \begin{align*}
            |x_N - x_n| < 1 \implies x_N - 1 < x_n < x_N + 1
        \end{align*}
        So the latter part of the sequence (beyond $N$) is bounded by $\max\{|x_N + 1|, |x_N - 1|\}$. Then part of the sequence from $x_1$ to $x_{N-1}$ is finite, meaning that it is bounded by $\max\{|x_1|, ..., |x_{N-1}|\}$. Letting $M = \max\{|x_1|, ..., |x_{N-1}|, |x_N + 1|, |x_N - 1|\}$, the entire sequence is bounded between $-M$ and $M$.
        \item Now that we know that $(x_n)$ is bounded, we can apply Theorem \ref{thm:bw} to say that there is a convergent subsequence $(x_{n_k})_{k=1}^\infty$. Say this subsequence converges to $x$. In the next step, we will show that $(x_n)$ also converges to $x$.
        \item Take any $\epsilon$. Choose $K$ such that for all $k \geq K$, 
        $|x_{n_k} - x| < \frac{\e}{2}$ (we can do so because the subsequence converges). Then, choose $N_1 > n_K$. Next, let $N_2$ be large enough such that $|x_k - x_l| < \frac{\e}{2}$ (we can do so because $(x_n)$ is Cauchy). Let $N = \max\{N_1, N_2\}$, so that both conditions are satisfied for $n \geq N$. For any $n \geq N$, we have
        \begin{align*}
            |x_n - x| = |x_n - x_{n_K} + x_{n_K} - x| \leq |x_n - x_{n_K}| + |x_{n_K} - x| \leq \frac{\e}{2} + \frac{\e}{2} = \e
        \end{align*}
        The first term is bounded because $n \geq N_2$ and the second term is bounded because $n \geq N_1$. By definition, $(x_n)$ converges to $x$.
    \end{enumerate}
\end{proof}

\section{January 15, 2020}

We'll start with a few sequence problems just to review. First note that the following are equivalent for $x_n, x \in \R$ and $\epsilon > 0$.
\begin{align*}
    |x_n - x| \leq \epsilon \iff x - \epsilon \leq x_n \leq x + \epsilon
\end{align*}
\begin{exc}
    Let $(a_n) \rightarrow L$, $(b_n) \rightarrow L$, and $a_n \leq b_n \leq c_n$ for all $n$. Prove that $(b_n) \rightarrow L$. (This is usually referred to as the Squeeze Theorem)
\end{exc}
\begin{exc}
    Let $(x_n)$ be momnotonically non-decreasing and $(y_n)$ be monotonically non-increasing, and $x_n \leq y_n$ for all $n$. Prove that both of these sequences converge (You will have to use a result from last time). 
\end{exc}
\begin{exc}
    Let $C \in \R$ with $|C| < 1$. Prove that $C^n \rightarrow 0$.
\end{exc}
\begin{exc}
    Show that $\frac{n!}{n^n} \leq \frac{1}{n}$. Then, compute the limit of $(x_n)$ with $x_n = \frac{n!}{n^n}$.
\end{exc}
\begin{exc}
    Let $a \neq b$. Discuss the convergence of the sequence $(x_n)$, with
    \begin{align*}
        x_n = \frac{a^n - b^n}{a^n + b^n}
    \end{align*}
\end{exc}
\begin{exc}
    Let $(x_n) \rightarrow L > 0$. Prove that there is an $N$ such that for all $n \geq N$, $x_n > \frac{L}{2}$.
\end{exc}

\begin{exm}
    What is the supremum and infimum of $\{\frac{(-1)^n}{n} : n = 1, 2, 3, ...\}$?
\end{exm}
\begin{exm}
    Let $0 < r < 1$ be fixed. What is the supremum and infimum of $\{(1+\frac{r}{n})^n : n = 1, 2, 3, ...\}$? 
\end{exm}
\begin{exm}
    What is the supremum and infimum of $[0, 10) = \{x: 0 \leq x < 10\}$? 
\end{exm}

We will now move into a subfield called topology, in which we discuss the shape, boundaries, and other properties of sets in space.
\begin{defi}[Open Set]
    A set $A \sse \R$ is called open if for every $x \in A$, there is an $\e > 0$ such that $(x - \e, x + \e) \sse A$.
\end{defi}
This is the type of set that has ``no boundaries". Similar to the limit-type proofs, you must show that for every element of the set, a small interval around that element is still fully contained in the set.
\begin{exm}
    Prove that the interval $(0, 1)$ is open.
\end{exm}
\begin{proof}
    Take any $x \in (0, 1)$. Letting $\e = \min\{x, 1 - x\}$, we are assured that $(x - \e, x + \e) \sse A$.
\end{proof}
Draw a picture of the previous example if it is unclear. Note that by convention, the empty set $\emptyset$ is open. We prove some basic properties about open sets.
\begin{exm}
    Prove that the union of two open sets is open.
\end{exm}
\begin{proof}
    Let $A$ and $B$ be open sets. We want to show that $A \cup B$ is open. Let $x \in A \cup B$. One or both of the following could be true.
    \begin{enumerate}
        \item $x \in A$. Because $A$ is open, there is $\e$ such that $(x - \e, x + \e) \sse A \sse A \cup B$.
        \item $x \in B$. Because $B$ is open, there is $\e$ such that $(x - \e, x + \e) \sse B \sse A \cup B$.
    \end{enumerate}
    This choices of $\e$ are not required to be the same; they are individual cases.
\end{proof}
\begin{exm}
    Prove that the intersection of two open sets is open.
\end{exm}
\begin{proof}
    Let $A$ and $B$ be open sets. We want to show that $A \cap B$ is open. Let $x \in A \cap B$, i.e. $x \in A$ and $x \in B$. We know the following are both true. Because $A$ is open, there is $\e_1$ such that $(x - \e_1, x + \e_1) \sse A$. Because $B$ is open, there is $\e_2$ such that $(x - \e_2, x + \e_2) \sse B$. Letting $\e = \min\{\e_1, \e_2\}$, we can be assured that $(x - \e, x + \e) \sse A$ and $(x - \e, x + \e) \sse B$, meaning that $(x - \e, x + \e) \sse A \cap B$. Thus, $A \cap B$ is open.
\end{proof}

The same proof can show that a union of an arbitrary (possibly infinite) number of open sets is necessarily open. The same is not true of intersections, in that only a finite number of intersections will guarantee an open set. Which part of our proof breaks down for an infinite number of sets?
\begin{exm}
    Provide an example of an infinite number of open sets whose intersection is not open.
\end{exm}
\begin{proof}
    Let $A_n = (-\frac{1}{n}, \frac{1}{n})$. The intersection $A = \bigcap_{n=1}^\infty A_n = \{0\}$. A single point cannot be open, as any interval around that point would spill out of the set.
\end{proof}

Our next definition will be intuitively similar to a point "on the boundary".
\begin{defi}[Accumulation Point]
    $y \in \R$ is called an accumulation point (AP) of set $A$ if for any $\e$, there is an $x \in A$ such that
    \begin{align*}
        x \in (y - \e, y + \e) \text{ and } x \neq y
    \end{align*}
\end{defi}
This means that the point is close enough to the set that for every small interval around the point, there is an element of the set that is nearby and different. The following result establishes an equivalence.
\begin{thm}
    Let $y \in \R$ and $A$ be a set with $y \notin A$. $y$ is an AP of $A$ if and only if there exists a sequence $(x_n) \rightarrow y$ with $x_n \in A$ for all $n$.
    \label{thm:ap}
\end{thm}
\begin{proof}
    First assume that $y$ is an AP. We must construct a sequence (using the elements of $A$), that converges to $y$. To generate element $x_n$ of the sequence, consider the interval $(y - \frac{1}{n}, y + \frac{1}{n})$ about $y$. By definition of an $AP$, this must contain a point in $A$. Call that $x_n$. Now, given any $\e > 0$, the elements $x_n$ with $n > \frac{1}{\e}$ will be $\e$-close to $y$. Thus, this choice of $(x_n)$ clearly converges to $y$
    
    On the other hand, assume that such a sequence exists. By definition of a convergent sequence, we know that for any $\e$, there exists $N$ such that for all $n \geq N$, $|x_n - y| < \e \iff x_n \in (y - \e, y + \e)$ (there are an infinite number of points in this interval, but we only need one). Now we must only be sure that $y \neq x_n$. By assumption $x_n \in A$, while $y \notin A$, so that cannot be equal. The result is shown.
\end{proof}
Not that we did not use the fact that $y \notin A$ for the forward direction of the proof.

\section{January 16, 2020}

Review the definition of open set and accumulation point (AP) from last time. Now we characterize a set that includes its boundaries.
\begin{defi}[Closed Set]
    A set $A \sse \R$ is called closed if it contains all of its accumulation points.
\end{defi}
Simple examples include single points, bracketed intervals $[a, b]$, and the non-negative reals $[0, \infty)$.
\begin{exm}
    Prove that the union of two closed sets is closed.
\end{exm}
\begin{proof}
    Let $A$ and $B$ be closed. We must show that $A \cup B$ is closed. Accordingly, let $y$ be an AP of $A \cup B$. This should imply that it is a member of $A \cup B$. It is sufficient to show that $y$ is an AP of $A$ or an AP of $B$, because if $y$ was an AP of $A$, then it would be in $A$, as $A$ is closed. The same is true for $B$. If $y$ is in either set, then $y \in A \cup B$. We will show this by contrapositive, in that if $y$ is both not an AP of $A$ and not an AP of $B$, then it is not an AP of $A \cup B$. By assumption, we know that
    \begin{enumerate}
        \item $y$ is not an AP of $A$ implies that there exists $\e_1$ such that $(y - \e_1, y + \e_1)$ does not contain any $x \in A$ with $y \neq x$.
        \item $y$ is not an AP of $B$ implies that there exists $\e_2$ such that $(y - \e_2, y + \e_2)$ does not contain any $x \in B$ with $y \neq x$.
    \end{enumerate}
    Letting $\e = \min\{\e_1, \e_2\}$, the interval $(y - \e, y + \e)$ does not contain any $x$ in $A$ or in $B$ with $y \neq x$. Thus, $y$ is not an AP of $A \cup B$ and the result is shown.
\end{proof}
As you saw last time, this argument breaks down in the case an infinite number of sets. Therefore, only a the union of a finite number of closed sets is guaranteed closed.
\begin{exm}
    Give an example of an infinite union of closed sets that is not closed.
\end{exm}
Such an example could look like $A = \bigcup_{n=1}^\infty A_n$, where $A_n = \{\frac{1}{n}\}$. This set is missing $0$, as it is an AP. For homework, you will prove the following.
\begin{exc}
    Prove that the intersection of two closed sets is closed.
\end{exc}
Unfortunately, it is not true that a set that is ``not open" is automatically "closed". We can find sets that are both and neither (see the concluding examples). However, there is a relationship.
\begin{defi}[Set Complement]
    The set complement $A^c$ of set $A$ in $\R$ is defined as $A^c = \{x \in \R: x \notin A\}$.
\end{defi}

\begin{exc}
    Show using Venn diagrams or De Morgan's laws that $(A \cup B)^c = A^c \cap B^c$ and that $(A \cap B)^c = A^c \cup B^c$.
\end{exc}
The establish the following two results.
\begin{thm}
    If $A \sse \R$ is closed, then $A^c$ is open.
\end{thm}
\begin{proof}
    Let $A$ be closed, and let $x$ be any point in $A^c$. We are confident that $x$ is not an AP of $A$, because then it would be contained in $A$, as as $A$ is closed. So it must be true by the (negated) definition of an AP, there is an $\e > 0$ such that $(x - \e, x + \e)$ contains no points of $A$. We rule out the case that the interval contains a point in $A$ that is equal to $x$, as $x \in A^c$. The entire interval $(x - \e, x + \e)$ is thus contained in $A^c$, as all of the points are not in $A$. By definition, $A$ is open.
\end{proof}
\begin{thm}
    If $A \sse \R$ is open, then $A^c$ is closed.
\end{thm}
\begin{proof}
    Let $A$ be open, and let $y$ be an AP of of $A^c$. Assume for the sake of contradiction, that $y \notin A^c$, i.e. $y \in A$. If so, then for all $\e$, $(y - \e, y + \e)$ contains a point in $A^c$, by definition of an AP. But then, no interval about $y \in A$ is fully contained in $A$, as it would always contain a point in $A^c$. Thus, $A$ is not open. This, however, is a contradiction, and our assumption that $y \notin A^c$ is false. Thus, $y \in A^c$, and $A^c$ is hence closed.
\end{proof}
Another way to phrase the two results in one is by saying that ``$A$ is open if and only if $A^c$ is closed" (work this out using contrapositives!). 

\begin{exc}
    Prove that $\R$ and the empty set $\emptyset$ are both open and closed.
\end{exc}
\begin{exc}
    Provide an example of a set that is neither open nor closed.
\end{exc}
\begin{exc}
    Let $A = \{x : x \text{ is rational.}\}$. Is $A$ open, closed, both, or neither?
\end{exc}
\begin{exc}
    Let $A = \{x : x \text{ is irrational.}\}$. Is $A$ open, closed, both, or neither?
\end{exc}
\begin{exc}
    Let $A = \bigcap_{n=1}^\infty [-2, \frac{1}{n})$. Is $A$ open, closed, both, or neither?
\end{exc}

We now approach our final topological term - compactness. There are a few ways to view this concept. We use compactness to describe the sets that have similar properties when deformed continuously (in ways such as stretching, shrinking, etc.). We can also think of it as those sets that have its elements tightly-packed, with no holes, and no escaping the set. Before the definition, we give a characterization that will help you think about what kinds of sets are compact.
\begin{thm}[Heine-Borel]
    A set $A \in \R$ is compact if and only if it is closed and bounded.
    \label{thm:hb}
\end{thm}
While we will only work with this in $\R$ mathematically, it is helpful to visualize this in $\R^2$. See Figure \ref{fig:compact}.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/compact.png}
    \caption{The shaded regions represent elements of the set, with solid and dotted boundaries denoting inclusion and exclusion, respectively. The top-left and bottom-right are compact sets in $\R^2$.}
    \label{fig:compact}
\end{figure}
Now, we look at the definition, which is a little bit more elusive.
\begin{defi}[Compact Set]
    A set $A \in \R$ is compact if for every sequence $(x_n)$ with $x_n \in A \ \forall n$, $(x_n)$ has a subsequence that converges in $A$.
\end{defi}
This can be thought of as all sequences being ``trapped" in $A$, unable to escape to another element even in the limit. We will prove \ref{thm:hb} in pieces.
\begin{exm}
    Prove that a compact set is closed.
\end{exm}
\begin{proof}
    We prove this by contrapositive. Assume set $A$ is not closed. Then, there must exist an AP $y$ of $A$ that lies outside of $A$. By \ref{thm:ap}, we know that there exists a sequence $(x_n)$ with each element in $A$ that converges to $y$. Because $(x_n) \rightarrow y$, any subsequence $(x_{n_k}) \rightarrow y \notin A$. Because we found a sequence in $A$ that does not have a subsequence converging in $A$, $A$ is not compact.
\end{proof}

\section{January 21, 2020}

While we saw a definition of compactness last time, there is an alternate definition that we can also get some mileage out of.
\begin{defi}[Open Cover]
    A collection of sets $\mathcal{S}$ is called an open cover of set $A$ if for all $U \in \mathcal{S}$, $U$ is open, and
    \begin{align*}
        A \sse \bigcup_{U \in \S} U
    \end{align*}
\end{defi}
This is a collection (or set) or sets such that when we take their union, we get a larger set that contains all of $A$. Note that I did not write something like $\bigcup_{n=1}^\infty U_n$, because there is no need for the sets to be indexed by the natural numbers. In other words, there is no need for the group of sets to be countable. This will yield the following definition.
\begin{defi}[Compact Set]
    A set $A \sse \R$ is compact if every open cover of $A$ has a finite subcover.
\end{defi}
By subcover, we mean a subset of $\S$ that is still an open cover of $A$. Note that the definition is not that a finite open cover exists, but rather given any (possibly infinite) open cover, you can extract a finite subcover from it. Figure \ref{fig:subcover} visualizes this.
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/finite_subcover.png}
    \caption{The brown ellipse represents a set, and the blue ellipses represent an open cover. Note that compactness does not require the existence of an open cover, but for every given (even infinite) open cover, one can extract a finite subcover.}
    \label{fig:subcover}
\end{figure}
Going back to Heine-Borel, we know that every closed and bounded set in $\R$ is compact, including the closed intervals and singletons. Let us go through a negative example.
\begin{exm}
    Prove that $A = (0, 1)$ is not compact.
\end{exm}
\begin{proof}
    To negate the definition that every open cover has a finite subcover, we must construct an open cover that does not have a finite subcover. Consider the sets $U_n = (\frac{1}{2^n}, \frac{3}{2^n})$, and consider the collection $\S = \{U_n: n = 1, 2, ...\}$. This is clearly an open cover of $A$ (draw a picture!). How can we show that there is no finite subcover? Because this collection is infinite, we must remove some open sets in order to have a finite subcover. However, any set that we remove reveals an uncovered portion of $A$. Indeed, when removing $U_1$, we lose coverage of $[\frac{3}{4}, 1)$, and when removing $U_n$ for $n > 1$, we lose coverage of $[\frac{3}{2^{n+1}}, \frac{1}{2^{n-1}}]$. Thus, no finite subcover exists, and $A$ is not compact. 
\end{proof}
Why will the same argument not hold for $[0, 1]$? For one, this collection does not cover $\{0\}$. If we include a small ball $(-\e, \e)$ around 0 in the open cover, then we can remove an infinite amount of the $U_n$ from within that ball. Precisely, once the end point $\frac{3}{2^n} < \e$, then we do not need $U_n$. We already know that compact sets are closed. Let's use this to show that they are bounded.

\begin{exm}
    Prove that a compact set is bounded.
\end{exm}
\begin{proof}
    Let $A$ be a compact set. Consider the collection $\S = \{(-r, r) : r > 0\}$. $\bigcup _{r > 0} (-r, r) = \R$, so this is definitely an open cover of $A$. By compactness, there exists a finite subcover $\S_f = \{(-r_1, r_1), ..., (-r_N, r_N)\}$. Let $r = \max\{r_1, ..., r_N\}$. Then, $A \sse (-r ,r)$, and this thus bounded.
\end{proof}
In order to work towards the converse of Heine-Borel (showing that closed and bounded sets in $\R$ are compact), we will need one more result.
\begin{thm}
    Let $B$ be compact and $A$ be a closed subset of $B$. Prove that $A$ is also compact.
    \label{thm:subset}
\end{thm}
\begin{proof}
    Let $\S$ be an open cover of $A$. We want to show that it has a finite subcover. Let $U = A^c$, i.e. all of $\R$ excluding $A$. Becuase $A$ is closed, $U$ is open. Therefore, $\S \cup U$ is an open cover of all of $\R$, and thus an open cover of $B$. Because $B$ is compact, there is a finite subcover $\S_f$ of $\S \cup U$ that covers all of $B$. This finite $\S_f$ must then also cover $A$, as $A \sse B$. $U$ was not in the original $\S$, and might be in $\S_f$. However, because $U$ contains no points of $A$, we can discard $U$ from $\S_f$ and we have thus extracted from $\S$ a finite subcover of $A$.
\end{proof}
While we have taken this for granted, we will also formally show the following.
\begin{exm}
    Prove than a closed interval $[a, b]$ is compact. 
    \label{thm:interval}
\end{exm}
\begin{proof}
    In this case, we will use the sequential definition. Let $(x_n)$ be a sequence in $[a, b]$. By \ref{thm:mono}, we know that this $(x_n)$ has a monotone subsequence. This monotone subsequence is bound below by $a$ and above by $b$, so we know that by Homework 1 Problem 3, the subsequence converges to some limit $x$. $a \leq x \leq b$, and because $a, b \in [a, b]$, we are assured that $x \in [a, b]$. 
\end{proof}
We are now in a place to show the following.
\begin{exm}
    Prove that if a set in $\R$ is closed and bounded, then it is compact.
\end{exm}
\begin{proof}
    Let $A sse \R$ be bounded, i.e. there is some $M$ such that for all $x \in A$, $-M \leq |x| \leq M$. Then, $A \sse [-M, M]$ (\ref{thm:interval}). $A$ is also closed, in particular a closed subset of the compact set $[-M, M]$. Then, by \ref{thm:subset}, $A$ is compact.
\end{proof}

\subsection*{Functions}

\begin{itemize}
    \item A function $f$ takes elements of set $A$ and maps/corresponds them to elements of set $B$. We write this as $f: A \rightarrow B$.
    \item If $x \in A$ corresponds to $y \in B$, we write $y = f(x)$. For example, take a function $f: \R \rightarrow \R$ defined by $f(x) = x^2$; it maps $x \in \R$ to $y = x^2 \in \R$.
    \item $A$ is called the {\it domain} of $f$ and $B$ is called the {\it codomain} of $f$.
    \item The {\it image} or {\it range} of $f$ is the set of all points that can be achieved by plugging in values into $f$, or all possible outputs of $f$. That is, $\text{image}(f) = \{f(x) : x \in \text{domain}(f)\}$.
    \item $\text{image}(f) \subseteq \text{codomain}(f)$. The reason that they are not necessarily equal is that all points in the codomain need not be achieved by plugging in values into $f$. For $f(x) = x^2$, the codomain is $\R$, but only the nonnegative numbers in $\R$ are possible outputs of $f$.
    \item Functions can be of multiple variables, such as $z = f(x,y) = 2x + y$. Here, we usually call $z$ the {\it output} or {\it value} of the function, while $x$ and $y$ are called {\it inputs} or {\it arguments} to the function.
    \item A function is {\it one-to-one} if different points in the domain map to different points in the codomain. That is, $x \neq y \implies f(x) \neq f(y)$, or that $f$ preserves distinctness.
    \item Finally, $f$ is {\it onto} if $\text{image}(f) = \text{codomain}(f)$, or that for every $y \in \text{codomain}(f)$, there exists an $x \in \text{domain}(f)$ such that $y = f(x)$.
\end{itemize}
\newpage
Understand the following examples:
\begin{enumerate}
    \item $f: \R \rightarrow \R$ defined by $f(x) = x^2$ is not onto. If we define the function instead as $f: \R \rightarrow \R_{\geq 0}$ where $\R_{\geq 0} = [0, \infty)$, then $f$ is onto. More generally, a function can always be made onto by restricting the codomain to just the range/image.
    \item $f: \R \rightarrow \R$ is one-to-one if it passes the horizontal line test, i.e. no horizontal line crosses the plot of the function more than once.
    \item For any constant $R$, take $f: [-R,R] \rightarrow \R$ defined by $f(x) = \sqrt{R^2-x^2}$. $\text{image}(f) = [0,R]$. Why is $\text{domain}(f)$ restricted to $[-R,R]$?
    \item If you have taken linear algebra: take $f: \R^n \rightarrow \R^m$ defined by $f(x) = Ax$ for some $m \times n$ matrix $A$. Why is $\text{image}(f) = \text{span}\{\text{columns of $A$}\}$?
\end{enumerate}

You have likely seen, at least conceptually, {\bf continuous} functions in your calculus class. When the function $f: \R \rightarrow \R$, this amounts to $f$ being drawn from without lifting the pen from the paper. How can one write precisely what it means for a function to be continuous, in a way that can be proven? For the remainder of the notes, we will assume that the sets $\X \sse \R$ and $\Y \sse \R$.
\begin{defi}[Continuous function]
    A function $f: \X \rightarrow \Y$ is called continuous at point $x_0 \in \X$ if for any $\e > 0$, there is a $\delta > 0$ (dependent on $\e$ and $x_0$), such that
    \begin{align*}
        |x - x_0| < \delta \implies |f(x) - f(x_0)| < \e
    \end{align*}
    $f$ is called continuous if it is continuous at any points $x_0 \in \X$.
\end{defi}
This is just another ``you give me an $\e$, I give you a $\delta$" type of definition, and the proofs are all the same style. Given an $\e$, you must compute or show non-constructively the existence of such a $\delta$.
\begin{exm}
    Prove that the $f(x) = 3x$ is continuous.
\end{exm}
\begin{proof}
    Take any $x_0$, and $\e > 0$. Let $\delta = \frac{\e}{3}$.
    \begin{align*}
        |f(x) - f(x_0)| = |3x - 3x_0| = 3|x - x_0| < 3\delta = \e
    \end{align*}
\end{proof}
The following is a more involved example, where the choice of $\delta$ must depend on $x_0$.
\begin{exm}
    Prove that $f(x) = \frac{1}{x}$ on $\X = \{x : x > 0\}$ is continuous.
\end{exm}
\begin{proof}
    Take any $x_0$, and $\e > 0$. Let's work backwards.
    \begin{align*}
        |f(x) - f(x_0)| = \frac{|x_0 - x|}{x x_0} 
    \end{align*}
    The top will be bounded by whatever $\delta$ we choose, but the bottom will be pesky, as it can be arbitrarily small (remember that $\delta$ cannot depend on $x$, only $x_0$). First, we will put a closeness restriction on any $x$ that we consider. If we ensure that $\delta < \frac{x_0}{2}$, then this means that $|x - x_0| < \delta \implies x > \frac{x_0}{2}$ (try drawing this on the positive number line). Keeping that in mind, let's see where we get.
    \begin{align*}
        \frac{|x_0 - x|}{x x_0} < \frac{2|x_0 - x|}{x_0^2}
    \end{align*}
    Now we are in a good spot. If we also have that $\delta < \frac{\e x_0^2}{2}$, then
    \begin{align*}
        \frac{2|x_0 - x|}{x_0^2} < \frac{2 x_0^2 \e}{2 x_0^2} = \e
    \end{align*}
    To ensure both conditions on $\delta$, let $\delta = \frac{1}{2} \min\{\frac{x_0}{2}, \frac{\e x_0^2}{2}\}$ and we are done.
\end{proof}

\section{January 22, 2020}

We will start by showing one of the most important properties of continuous functions.
\begin{thm}
    Let $f: \X \rightarrow \R$ be a continuous function. Let sequence $(x_n) \rightarrow x_0 \in \X$, with each $x_n \in \X$. Then $(f(x_n)) \rightarrow f(x_0)$ as $n \rightarrow \infty$.
\end{thm}
Before we show this, try to think of a negative example.
\begin{proof}
    Take any $\e > 0$. Let $\delta > 0$ be the number so that $|x - x_0| < \delta \implies |f(x) - f(x_0)| < \e$. We are assured of its existence because of the continuity of $f$, in particular at the point $x_0$. Then, let $N$ be large enough such that $|x_n - x_0| < \delta$ for $n \geq N$ (we know that there is such an $N$ because $x_n \rightarrow x$). Then, we have $|f(x_n) - f(x_0)| < \e$ for all $n \geq N$.
\end{proof}

For the following domains and codomains, assume all are subsets of $\R$.
\begin{defi}[Inverse Image or Preimage]
    Let $f: \X \rightarrow \Y$ be a function. Let $B \sse \Y$ be a set. $f^{-1}(B) := \{x: f(x) \in B\}$ is called in inverse image (or preimage) of $f$ at $B$.
\end{defi}
\begin{exm}
    Prove that $f^{-1}(B^c) = (f^{-1}(B))^c$.
\end{exm}
\begin{proof}
    \begin{align*}
        x \in  f^{-1}(B^c) \iff f(x) \in B^c \iff f(x) \notin B \iff x \notin f^{-1}(B) \iff x \in (f^{-1}(B))^c
    \end{align*}
\end{proof}

\begin{thm}
    Let $f: \X \rightarrow \Y$ be a continuous function. Let $B \sse \Y$ be open. Then $f^{-1}(B)$ is open.
\end{thm}
\begin{proof}
    Let $x_0 \in f^{-1}(B)$. We must show that there is some $\delta > 0$ such that $(x_0 - \delta, x_0 + \delta) \sse f^{-1}(B)$. We know that $f(x_0) \in B$ and that $B$ is open. Thus, there is an $\e > 0$ such that $(f(x_0) - \e, f(x_0) + \e) \sse B$. We know that by the definition of continuity, there there must exist a $\delta > 0$ such that TO DO. Any $x \in (x_0 - \delta, x_0 + \delta)$ has $f(x) \in (f(x_0) - \e, f(x_0)) \in B$, meaning that $(x_0 - \delta, x_0 + \delta) \in f^{-1}(B)$. Thus, $f^{-1}(B)$ is open.
\end{proof}

\begin{thm}
    Let $f: \X \rightarrow \Y$ be a continuous function. Let $B \sse \Y$ be closed. Then $f^{-1}(B)$ is closed.
\end{thm}
\begin{proof}
    \begin{align*}
        B \text{ closed} \implies B^c \text{ open} \implies f^{-1}(B^c) \text{ open} \implies (f^{-1}(B))^c \text{ open} \implies f^{-1}(B) \text{ closed}
    \end{align*}
\end{proof}

\begin{thm}
    Let $f: \X \rightarrow \Y$ be a continuous function. Let $A \sse \X$ be compact. Then $f(A)$ is compact.
\end{thm}
\begin{proof}
    Take any $(f(x_n))$, a sequence in $f(A)$. We must show that it has a convergent subsequence. We know that by compactness of $A$, that the sequence $(x_n)$ has a convergent subsequence, say $(x_{n_k}) \rightarrow x \in X$ (as $k \rightarrow \infty$). By continuity, the subsequence $(f(x_{n_k})) \rightarrow f(x) \in f(A)$. $(f(x_{n_k}))$ is clearly a subsequence of $(f(x_n))$ that converges in $f(A)$. Thus $f(A)$ is compact.
\end{proof}

The concept of continuity can be described alternatively by a ring that must slide across the length of the function without changing its orientation (See Figure \ref{fig:cont}). We will give a name to the types of functions who have the property that the width of the ring ($2\delta)$) does not depend on the center point $x_0$.
\begin{figure}
    \centering
    \includegraphics[width=0.494\linewidth]{figures/uniform.png}
    \includegraphics[width=0.494\linewidth]{figures/not_uniform.png}
    \caption{A pictorial characterization of continuity whether a ring of height $2\e$ and width $2\delta$ could slide along the entire function, without turning, for every $\e$. If $\delta$ must change as this happens, the the function is only continuous. In the right example, $\delta$ must get smaller as $x$ gets large in order for the ring to continue sliding. In the case that $\delta$ can stay constant, as in the left example, then the function is uniformly continuous.}
    \label{fig:cont}
\end{figure}
\begin{defi}
    A function $f: \X \rightarrow \Y$ is uniformly continuous if for every $\e > 0$, there is a $\delta > 0$ (dependent only on $\e$) such that for any $x_1, x_0 \in \X$,
    \begin{align*}
        |x_0 - x_1| < \delta \implies |f(x_0) - f(x_1)| < \e
    \end{align*}
\end{defi}
Uniform continuity describes those functions that do not change too rapidly in some interval. $f(x) = \frac{1}{x}$ is not uniformly continuous, as any ring would eventually ``crash" into the function if slide close enough to $x = 0$.
\begin{exm}
    Provide an example of a function that is unbounded but still uniformly continuous.
\end{exm}
$f(x) = x$ does the trick here. Letting $\delta = \e$ satisfies the definition.
\begin{exm}
    Provide an example of a function that is continuous and bounded but not uniformly continuous.
\end{exm}
In this case, we look to functions that oscillate at an arbitrarily large speed. Take $f(x) = \sin \frac{1}{x}$. As $x$ gets close to 0, the functions oscillates such that no ring could slide close to that region. Try plotting the function to confirm this.

We will end with a problem that allows us to practice the definition of uniform continuity by negating it.
\begin{exm}
    Prove that $f(x) = \frac{1}{x}$ for $x > 0$ is not uniformly continuous.
\end{exm}
\begin{proof}
    We want to show that there is some $\e > 0$, such that for all $\delta > 0$, there exist $x_0, x_1 \in \X$ such that $|x_0 - x_1| < \delta$, but $|f(x_0) - f(x_1)| \geq \e$. Note that $x_0, x_1$ can and will likely depend on $\delta$. Unravelling the second condition, we have
    \begin{align*}
        |f(x_0) - f(x_1)| = \frac{|x_0 - x_1|}{x_0 x_1}
    \end{align*}
    It seems intuitively that we can blow up this difference by making $x_0$ and $x_1$ small enough. Because we must have $|x_0 - x_1| < \delta$, let us fix $x_0$ and let $x_1 = x_0 + \frac{\delta}{2}$. So, we are guaranteed the first condition. Unravelling again,
    \begin{align*}
        \frac{|x_0 - x_1|}{x_0 x_1} = \frac{\delta}{2x_0(x_0 + \frac{\delta}{2})} = \frac{\delta}{2x_0^2 + \delta x_0} \overset{\text{want}}{\geq} 1
    \end{align*}
    We must find $x_0$ such that
    \begin{align*}
        2x_0^2 + \delta x_0 - \delta \leq 0
    \end{align*}
    This is a concave up parabola, so finding where it is less than zero is equivalent to finding its roots, and choosing any $x_0$ in between those roots. The discriminant is $\delta^2 - 4(2)(-\delta) = \delta^2 + 8\delta > 0$, so we are assured of real roots. Choose $x_0$ between these roots and we are done.
\end{proof}

We present one more theorem without proof, but try to motivate this yourself with a picture and some examples. You can also look up a proof in a text and see if you are able to understand all of the steps clearly.
\begin{thm}
    Let $f: \X \rightarrow \Y$ be continuous, with $\X$ compact. Then $f$ is uniformly continuous.
\end{thm}

\section{January 23, 2020}

Today we will debrief by going over what we covered in class, assessing our objectives and whether we met them, and taking/giving feedback.

\subsection*{Content}

In order to prove theorems, lemmas, exercises and the like, we must have content and definitions with which to work with. My mental view of the course two parts, each with a set of content with which to practice certain logic:
\begin{itemize}
    \item {\bf Part I: Fundamentals}
    \begin{itemize}
        \item Content: Definitions, Notation, Sets, Even/Odd Numbers, Prime/Composite Numbers.
        \item Logic: Direct/Contrapositive Proof, Proof by Contradiction, Proof by Induction
        \item Skills: Basic application of definitions and algebra to write your own proofs.
    \end{itemize}
    \item {\bf Part II: Rigorous Proof-Writing}
    \begin{itemize}
        \item Content: Infinity, Sequences, Limits, Cauchy Sequences, Open/Closed/Compact sets, Continuous and Uniformly Continuous functions.
        \item Logic: $\e-\delta$-style proofs.
        \item Skills: Applying critical thinking to understand new definitions and more complex arguments.
    \end{itemize}
\end{itemize}

By $\e-\delta$-style proofs, we mean all those that involve showing that ``for all something, there is a something" to satisfy a definition. For example
\begin{itemize}
    \item For all $\e > 0$, there is an $N$ such that ... (limit of a sequence)
    \item For all $x \in A$,  there is an $\e > 0$ such that ...(open set)
    \item For all sequences, there is a subsequence such that ... (compact set)
    \item For all $\e > 0$, there is a $\delta > 0$ such that ... (continuity)
\end{itemize}
These types of arguments make up a lot of the fields that deal with limits and infinity, and I will use $\e-\delta$ to describe all of them. In the examples that we have seen, coming up with the ``$\delta$" (whatever that means for the given problem) given any $\e$ usually comes down to:
\begin{itemize}
    \item Computing it. (Show that $(\frac{e^{-n}})$ converges to 0. Show that $(0, 1)$ is open. Show that $f(x) = \frac{1}{x}$ is continuous.)
    \item Non-constructively showing that it must exist. (Subsequence of a convergent sequence converges. Limit is carried through a continuous function.)
    \item Assuming that it does not exist, and contradicting. (If a set is open, its complement is closed.)
\end{itemize}
While I believe most problems you run into can be colved by iterating through these core principles, there are additional strategies that we sometimes used.
\begin{itemize}
    \item Adding additional constraints to the problem. (Provide an example of a perfect number less than 28, homework 2 problem 4.)
    \item Split into cases. (Every sequences has a monotone subsequence, homework 1 problem 2.)
    \item Write the beginning, then end, then middle of the proof. (Show that a compact set is closed.)
\end{itemize}

\subsection*{Objectives}

My broad goals for you all was to approach the ability to:
\begin{itemize}
    \item Think linearly and logically.
    \item Absorb complicated definitions through symbols, examples, and pictures.
    \item Argue with clarity and style.
    \item Learn independently.
\end{itemize}
I believe that all of these contribute to successful mathematics education, and if each of these improved a little over the course of three weeks, I would be happy with our progress.

\subsection*{Feedback}

I personally felt that the amount of material was a little bit ambitious, and what I wanted was to give more practice and have you read things before hand. I was kind of deciding which content to have as we were going along - as you can imagine, content is a lot deeper in a real analysis course and there were a lot of decisions made as to what content to keep to give enough practice with proof-writing. Now that I am more well accustomed to the pace of this material with freshmen and sophomores, I think that aspect can go a little smoother. Based on your feedback both in class on from Homework 2, we agreed on the following adjustments.
\begin{itemize}
    \item Speed: Slightly slower on pace.
    \item Material / Amount of practice: Slightly less material and more practice. One useful suggestion was a daily problem after each lecture, that we go over together the next day.
    \item Execution: Students seemed generally happy with presentation of material, as well as being called on to work through problems on the board. Another great suggestion was a minute or so to think about a new problem before taking volunteers to come up to the board.
\end{itemize}

Another general theme of feedback regarding the second half of the course was that while students could eventually understand and work through proofs that were given to them, they were unsure about how to decide which strategies or directions to pursue on their own. While I do think there is no algorithmic road map per se, iterating through the strategies we covered until one works is usually how you start. As you get more mathematical experience, you start having gut feelings as to which directions are going to be more fruitful than others, which previous results seem important to apply, etc.

\subsection*{Beyond this Class}

As for the material that we covered, I suggest going through the two textbooks for more problems. The Scheinerman book has a really clear exposition. I suggest going through each of the twenty or so proof templates that it has, and do a few examples associated with each one. This will branch our general approach to a few more specialized strategies that you can try in the future. The Aksoy book also has problems relating to the Part II of the course, that are a little harder than the ones that we covered. It has detailed solutions for every problem.

I have spent most of my time in the realm of applied mathematics and statistics, a little less in computer science, and less still in electrical engineering, so my suggestions will be a little biased towards those. If you want to improve your core mathematical skills, I recommend taking the actual Discrete Mathematics AMS course, the Honors Real Analysis I course in Math, Introduction to Proofs with Dr. Riehl, also in Math. As for other advanced courses with a proof-writing/theoretical component: 
\begin{itemize}
    \item Machine Learning (Arora)
    \item Algorithms (Dinitz)
    \item Matrix Analysis (Fishkind)
    \item Harmonic Analysis (Maggioni)
    \item Signals, Systems, and Learning (Venkataraman)
    \item Kinematics and Dynamics of Robots
    \item Dynamical Systems
    \item Partial Differential Equations
\end{itemize}
I suggested some professors who I know to be good to take these courses with. Working in statistics and machine learning, I absolutely run into proof-writing in my daily work (proving that algorithms/estimation procedures/hypothesis tests work in a certain way, etc.). If these topics interest you, and you would like to follow them into future coursework and research, let me know and we can discuss!

\subsection*{Thank you}

Thanks to you all for your helpful feedback and for taking this course. It was very education for me as well, and wish you all the best in the rest of your mathematical careers!

% BIBLIOGRAPHY AND ACKNOWLEDGEMENTS
% \paragraph{Acknowledgement} Thank you to the students that attended my section this semester. Your feedback has been extremely helpful, and I hope to see you all around in the spring! Good luck on the final!

% \newpage

% \vspace{5mm}
% \bibliography{refs}
% %\bibliographystyle{IEEEtran}
% \bibliographystyle{plainnat}

% \newpage

\end{document}

